# -*- coding: utf-8 -*-
"""Deep fake Detection using Resnet50 and MTCNN .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z7IwuEMUMpndFer4udlzKnHj5yezGnCg
"""

import zipfile
ref=zipfile.ZipFile("/content/drive/MyDrive/Deepfake Dataset New.zip")
ref.extractall('/content')
ref.close()

#list of useful libraries required for the project
import os
import tqdm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import cv2
from glob import glob
import seaborn as sns
import random
from keras.preprocessing import image
import tensorflow as tf

from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D,GlobalAvgPool2D,GlobalMaxPooling2D
from keras.optimizers import RMSprop
from keras.preprocessing.image import ImageDataGenerator

from keras.optimizers import Adam
from sklearn.model_selection import train_test_split

data=r'/content/Dataset'

images=[]
import os
for dirname,_,filenames in os.walk(data):
  for filename in filenames:
    file_name, file_extension = os.path.splitext(filename)
    if file_extension == '.db':
      continue
    else:
      img=os.path.join(dirname,filename)
      images.append(img)

images[:20]

len(images)

class_values = []
for i in images:
    j = i.split('/')
    class_values.append(j[-2])

class_values[:10]

len(class_values)

temp = list(zip(images,class_values))
random.shuffle(temp)
images, class_values = zip(*temp)
data = pd.DataFrame(list(zip(images, class_values)), columns=['image_path', 'Class_label'])

data

data.shape

data.Class_label.value_counts()

sns.countplot(x = data.Class_label, data = data)
plt.show()

from sklearn.utils import resample
# Separate majority and minority classes
df_c0 = data[data['Class_label']== 'Fake']
df_c1 = data[data['Class_label']== 'Real']


# Downsample majority class
df_c0_downsampled = resample(df_c0, replace=True,  n_samples = 35000,random_state=123)
df_c1_downsampled = resample(df_c1, replace=True,  n_samples = 35000,random_state=123)


# Combine minority class with downsampled majority class
df_downsampled = pd.concat([df_c0_downsampled,df_c1_downsampled])

# Display new class counts
df_downsampled['Class_label'].value_counts()

sns.countplot(x = df_downsampled.Class_label, data = df_downsampled)
plt.show()

df = df_downsampled.sample(frac=1)
df.head()

df['Class_label'].value_counts()

df.iloc[0,:-1]

import os
from PIL import Image

def resize_images(img):
  file = Image.open(img)
  img = file.convert('RGB')
  img_bgr= img.resize((224, 224))
  img_bgr = np.array(img_bgr)
  return img_bgr

images = [resize_images(img) for img in df['image_path']]

images

num_classes = len(np.unique(data['Class_label']))

num_classes

# save the class into class_names
class_names = list(data['Class_label'])
# Print the shape of the image
images[0].shape



#See the image with class label
plt.imshow(images[554])
plt.title(class_names[554])
plt.ylabel("Size", {"fontname": "serif", "fontweight":"bold"})
plt.xlabel("Size", {"fontname": "serif", "fontweight":"bold"})

#See the image with class label
plt.imshow(images[86])
plt.title(class_names[86])
plt.ylabel("Size", {"fontname": "serif", "fontweight":"bold"})
plt.xlabel("Size", {"fontname": "serif", "fontweight":"bold"})

#See the image with class label
plt.imshow(images[1088])
plt.title(class_names[1088])
plt.ylabel("Size", {"fontname": "serif", "fontweight":"bold"})
plt.xlabel("Size", {"fontname": "serif", "fontweight":"bold"})

images =  np.array(images)



images.shape

from sklearn.preprocessing import LabelBinarizer
enc = LabelBinarizer()
Y = enc.fit_transform(df['Class_label'])
from keras.utils  import to_categorical
y = to_categorical(Y)

enc.classes_

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.3,stratify = y,random_state=42)

X_train.shape

X_test.shape

import tensorflow as tf

from tensorflow.keras.applications.resnet50 import ResNet50

from keras.applications import ResNet101

net = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

net.trainable=False



model_net=Sequential()
model_net.add(net)
model_net.add(Flatten())
model_net.add(Dense(128, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(128, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(64, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(32, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(32, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(32, activation='relu'))
model_net.add(Dropout(0.2))
model_net.add(Dense(2, activation='softmax'))

#Compile the model
opt = Adam(lr=0.001)

optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)
model_net.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics = ["accuracy"])

History_net = model_net.fit(X_train, y_train, epochs = 22, validation_data = (X_test,y_test),batch_size = 128 )

import tensorflow as tf
def load_Resnet100():
  model_path = '/content/ResNet100_model.h5'  # path to your model
  model = tf.keras.models.load_model(model_path) #load your model
  return model

model = load_Resnet100()

# plot the accuracy plot
plt.plot(model.history['accuracy'], 'r')
plt.plot(model.history['val_accuracy'], 'b')
plt.legend({'Train Accuracy': 'r', 'Test Accuracy':'b'})
plt.ylabel("Accuracy", {"fontname": "serif", "fontweight":"bold"})
plt.xlabel("Epoch", {"fontname": "serif", "fontweight":"bold"})
plt.show()

#plot confusion matrix
from sklearn.metrics import confusion_matrix
class_names = enc.classes_
df_heatmap = pd.DataFrame(confusion_matrix(np.argmax((model.predict(X_test)),axis = 1),np.argmax(y_test,axis=1)),columns = class_names, index = class_names)
heatmap = sns.heatmap(df_heatmap, annot=True, fmt="d")

# print the test accuracy
score_5 = model.evaluate(X_test, y_test, verbose=0)
print('Test accuracy:', score_5[1])

model_net.save('ResNet50_model.h5')

!pip install MTCNN
import cv2
import numpy as np
import tensorflow as tf
from mtcnn.mtcnn import MTCNN

# Load pre-trained MTCNN model
detector = MTCNN()

def load_Resnet50():
  model_path = '/content/drive/MyDrive/ResNet50_model.h5'  # path to your model
  model = tf.keras.models.load_model(model_path) #load your model
  return model

model = load_Resnet50()

def preprocess_image(image, target_size=(224, 224)):
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB
  image = cv2.resize(image, target_size)
  image = image.astype('float32') / 255.0  # Normalize pixel values
  # ... (pre-processing steps, e.g., color normalization)
  return image

def detect_and_predict(image):

  # Detect faces with MTCNN
  faces = detector.detect_faces(image)
  if not faces:
    return None

  probabilities = []
  for face in faces:
    x, y, w, h = face['box']
    face_image = image[y:y+h, x:x+w]

    # Preprocess facial region
    face_image = preprocess_image(face_image)

    # Expand dimensions for model input (if needed)
    face_image = np.expand_dims(face_image, axis=0)

    # Predict deepfake probability
    probability = model.predict(face_image)[0][0]
    probabilities.append(probability)

  return probabilities

# Example usage
image = cv2.imread('/content/F_7TNI8WsAA4rh-.jpg')
probabilities = detect_and_predict(image)

if probabilities:

  for probability in probabilities:
    if probability >  0.5:  # Adjust threshold as needed
      print("Deepfake Image detected")
    else:
      print(" REAL Image detected ")
else:
  print("No faces found in the image.")

!pip install gradio
!pip install streamlit
!pip install MTCNN

import cv2
import numpy as np
import tensorflow as tf
from mtcnn.mtcnn import MTCNN
import gradio as gr

# Load pre-trained MTCNN model
detector = MTCNN()

def load_Resnet50():
  model_path = '/content/drive/MyDrive/ResNet50_model.h5'  # path to your model
  model = tf.keras.models.load_model(model_path) #load your model
  return model

model = load_Resnet50()

def preprocess_image(image, target_size=(224, 224)):
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB
  image = cv2.resize(image, target_size)
  image = image.astype('float32') / 255.0  # Normalize pixel values
  # ... (pre-processing steps, e.g., color normalization)
  return image

def detect_and_predict(image):

  # Detect faces with MTCNN
  faces = detector.detect_faces(image)
  if not faces:
    return None

  probabilities = []
  for face in faces:
    x, y, w, h = face['box']
    face_image = image[y:y+h, x:x+w]

    # Preprocess facial region
    face_image = preprocess_image(face_image)

    # Expand dimensions for model input (if needed)
    face_image = np.expand_dims(face_image, axis=0)

    # Predict deepfake probability
    probability = model.predict(face_image)[0][0]
    probabilities.append(probability)

  # Return "deepfake" if any probability is greater than 0.5, otherwise return "Real"
  return "deepfake" if any(p > 0.5 for p in probabilities) else "Real"

# Example usage

result = detect_and_predict(image)
print(result)

# Define Gradio interface
iface = gr.Interface(fn=detect_and_predict,
                     inputs="image",
                     outputs="text")

iface.launch()